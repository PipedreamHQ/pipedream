<template><h1 id="pipedream-sql-service" tabindex="-1"><a class="header-anchor" href="#pipedream-sql-service" aria-hidden="true">#</a> Pipedream SQL Service</h1>
<div class="custom-container danger"><p class="custom-container-title">DANGER</p>
<p>The SQL Service will shut down on February 10th, 2022. <a href="https://pipedream.com/blog/shutting-down-the-sql-service/" target="_blank" rel="noopener noreferrer">Read our blog post<ExternalLinkIcon/></a> for more details, and reach out to <a href="https://pipedream.com/support" target="_blank" rel="noopener noreferrer">Pipedream Support<ExternalLinkIcon/></a> with any questions.</p>
</div>
<p>Pipedream operates a hosted data warehouse as a <a href="/destinations/" target="_blank" rel="noopener noreferrer">Destination<ExternalLinkIcon/></a> you can send events to from a workflow. You can run SQL on any JSON you send here. We call this the <strong>SQL Service</strong>.</p>
<p>Using the SQL Service is simple:</p>
<ol>
<li><a href="#adding-a-sql-destination">Send data to the SQL Service from a workflow</a></li>
<li><a href="https://pipedream.com/sql" target="_blank" rel="noopener noreferrer">Run SQL on that data<ExternalLinkIcon/></a></li>
</ol>
<p>You don't need to create a table or define a schema for that table before you send data. The SQL service automatically manages the schema from your data, adjusting as the structure of the data changes. <strong>Send JSON, write SQL — that's it</strong>.</p>
<p>The SQL Service is an <strong>append-only database</strong>. This means you cannot update or delete records you send to it - it's optimized for <strong>logging events</strong> from your workflows: webhook requests, errors, or other events generated by your APIs or workflows. The Pipedream SQL Service isn't a replacement for a data warehouse, but it's a simple way to start asking complex questions about your data.</p>
<nav class="table-of-contents"><ul><li><RouterLink to="#adding-a-sql-destination">Adding a SQL Destination</RouterLink><ul><li><RouterLink to="#adding-a-pipedream-sql-action">Adding a Pipedream SQL Action</RouterLink></li><li><RouterLink to="#using-send-sql">Using $.send.sql()</RouterLink></li></ul></li><li><RouterLink to="#what-happens-when-you-send-data-to-a-sql-destination">What happens when you send data to a SQL Destination</RouterLink><ul><li><RouterLink to="#new-table">New table</RouterLink></li><li><RouterLink to="#existing-table">Existing table</RouterLink></li><li><RouterLink to="#mapping-json-data-types-to-presto-types">Mapping JSON data types to Presto types</RouterLink></li><li><RouterLink to="#fields-with-values-of-variable-types">Fields with values of variable types</RouterLink></li></ul></li><li><RouterLink to="#data-retention">Data Retention</RouterLink></li><li><RouterLink to="#running-sql-queries-from-the-ui">Running SQL queries from the UI</RouterLink><ul><li><RouterLink to="#limits">Limits</RouterLink></li><li><RouterLink to="#keyboard-shortcuts">Keyboard Shortcuts</RouterLink></li><li><RouterLink to="#downloading-your-results">Downloading your results</RouterLink></li><li><RouterLink to="#sql-dialect">SQL dialect</RouterLink></li><li><RouterLink to="#sql-queries-we-prevent">SQL queries we prevent</RouterLink></li></ul></li><li><RouterLink to="#running-sql-queries-via-api">Running SQL queries via API</RouterLink></li><li><RouterLink to="#running-sql-queries-from-a-workflow">Running SQL queries from a workflow</RouterLink></li><li><RouterLink to="#triggering-workflows-on-scheduled-sql-queries">Triggering workflows on scheduled SQL queries</RouterLink></li><li><RouterLink to="#query-limits">Query Limits</RouterLink></li><li><RouterLink to="#limitations-on-pipedream-sql-table-names">Limitations on Pipedream SQL table names</RouterLink></li><li><RouterLink to="#how-we-handle-non-json-data-sent-to-sql-destinations">How we handle non-JSON data sent to SQL Destinations</RouterLink></li><li><RouterLink to="#still-have-questions">Still have questions?</RouterLink></li></ul></nav>
<h2 id="adding-a-sql-destination" tabindex="-1"><a class="header-anchor" href="#adding-a-sql-destination" aria-hidden="true">#</a> Adding a SQL Destination</h2>
<h3 id="adding-a-pipedream-sql-action" tabindex="-1"><a class="header-anchor" href="#adding-a-pipedream-sql-action" aria-hidden="true">#</a> Adding a Pipedream SQL Action</h3>
<p>Adding a new SQL Destination to your workflow is easy. First, add a new step to your workflow and choose the <strong>Send JSON to Pipedream SQL Service</strong> action.</p>
<p>Then, add the <strong>Table Name</strong> and <strong>Payload</strong> you want to send to the SQL Destination. You can name the table whatever you want, within the <a href="#limitations-on-pipedream-sql-table-names">restrictions we impose on table names</a>.</p>
<div>
<img alt="Sending data to SQL table using the action" src="@source/destinations/sql/images/send-data-to-sql-table.png">
</div>
<p>The <strong>Payload</strong> must be a JavaScript object or reference a JavaScript object like <code>event</code> or <code>steps</code>. The <strong>Payload</strong> cannot be an arrays of JavaScript objects. If you need to send an array of objects to a SQL table, <a href="#using-send-sql">send them in a loop, using <code>$.send.sql()</code></a>.</p>
<p>Typically, your <strong>Payload</strong> will be something like <code>event</code>, <code>event.body</code> or a <a href="/workflows/steps/#step-exports" target="_blank" rel="noopener noreferrer">step export<ExternalLinkIcon/></a> like <code>steps.nodejs.myData</code>.</p>
<h3 id="using-send-sql" tabindex="-1"><a class="header-anchor" href="#using-send-sql" aria-hidden="true">#</a> Using <code>$.send.sql()</code></h3>
<p>You can send data to a SQL Destination in <a href="/workflows/steps/code/" target="_blank" rel="noopener noreferrer">Node.js code steps<ExternalLinkIcon/></a>, too, using the <code>$.send.sql()</code> function. <strong>This allows you to send data to the SQL Destination programmatically, if you need more control than Actions afford</strong>.</p>
<p><code>$.send.sql()</code> takes the same parameters as the corresponding Action:</p>
<div class="language-javascript ext-js line-numbers-mode"><pre v-pre class="language-javascript"><code>$<span class="token punctuation">.</span>send<span class="token punctuation">.</span><span class="token function">sql</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
  <span class="token literal-property property">table</span><span class="token operator">:</span> <span class="token string">"your_table_name"</span><span class="token punctuation">,</span>
  <span class="token literal-property property">payload</span><span class="token operator">:</span> event<span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>Like with any <code>$.send</code> function, you can use <code>$.send.sql()</code> conditionally, within a loop, or anywhere you'd use a function normally in Node.js.</p>
<p>For example, if you have an array of JavaScript objects, and you want to add <em>each</em> object as a new row to a table in the SQL Service, you can iterate over the array and send each object like so:</p>
<div class="language-javascript ext-js line-numbers-mode"><pre v-pre class="language-javascript"><code><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">const</span> payload <span class="token keyword">of</span> your_array_of_objects<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  $<span class="token punctuation">.</span>send<span class="token punctuation">.</span><span class="token function">sql</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token literal-property property">table</span><span class="token operator">:</span> <span class="token string">"your_table_name"</span><span class="token punctuation">,</span>
    payload<span class="token punctuation">,</span>
  <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><a href="https://pipedream.com/@dylburger/send-an-array-of-javascript-objects-to-the-sql-service-p_xMCJrm/edit" target="_blank" rel="noopener noreferrer">Copy this workflow<ExternalLinkIcon/></a> for a working example.</p>
<h2 id="what-happens-when-you-send-data-to-a-sql-destination" tabindex="-1"><a class="header-anchor" href="#what-happens-when-you-send-data-to-a-sql-destination" aria-hidden="true">#</a> What happens when you send data to a SQL Destination</h2>
<p>Our goal is to make it easy for you to query event data via SQL, without any of the operational headache of maintaining a full data warehouse, or setting up table schemas manually. We take care of that for you.</p>
<p>Because we're handling this setup behind the scenes, we'd like to discuss how the data sent to SQL Destinations is processed and how we generate table schemas.</p>
<p>First, <strong>payloads sent to SQL Destinations are batched and sent to the SQL service once a minute as a group. Therefore, the first event you send to a SQL Destination will take roughly one minute to be available for querying</strong>.</p>
<p><strong>The SQL service expects a JavaScript object as payloads</strong>. <a href="#how-we-handle-non-json-data-sent-to-sql-destinations">Read more below</a>.</p>
<p>Once delivered, we create tables and process the schema according to the following rules.</p>
<h3 id="new-table" tabindex="-1"><a class="header-anchor" href="#new-table" aria-hidden="true">#</a> New table</h3>
<p>If this is the first time you've sent data for the <strong>Table</strong> name you added in the SQL Destination, we:</p>
<ul>
<li>Create this table, and</li>
<li>Process all payloads included in the first batch of events, creating the schema for this table based on the structure of their fields and the data types of their values.</li>
</ul>
<p>Let's walk through some examples to see how this works.</p>
<p>Assume we create a new table called <code>my_test_table</code>, and we send the following two events:</p>
<div class="language-json ext-json line-numbers-mode"><pre v-pre class="language-json"><code><span class="token punctuation">{</span> <span class="token property">"event_type"</span><span class="token operator">:</span> <span class="token string">"click"</span><span class="token punctuation">,</span> <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1557349719</span> <span class="token punctuation">}</span>
<span class="token punctuation">{</span> <span class="token property">"event_type"</span><span class="token operator">:</span> <span class="token string">"open"</span><span class="token punctuation">,</span> <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1557349721</span><span class="token punctuation">,</span> <span class="token property">"username"</span><span class="token operator">:</span> <span class="token string">"test_user"</span> <span class="token punctuation">}</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>We examine the first event, which includes <code>event_type</code> — which we mark as a <code>STRING</code> — and <code>ts</code> — which we mark as a <code>DOUBLE</code> (see <a href="#mapping-json-data-types-to-presto-types">how we map JSON data types to Presto types</a>).</p>
<p>We record that schema and process the second event. This event includes the same two fields, with the same data types, but also includes a <em>third</em> field: <code>username</code>. This field is also marked as a Presto <code>STRING</code>.</p>
<p>The first event contained two fields, and the second event contained three fields. <strong>The resulting schema needs to capture the <em>union</em> of the fields <em>across</em> events, capturing all three fields</strong>.</p>
<p>In this example, the schema for the <code>my_test_table</code> table is:</p>
<ul>
<li><strong><code>event_type</code></strong> : <code>STRING</code></li>
<li><strong><code>ts</code></strong> : <code>DOUBLE</code></li>
<li><strong><code>username</code></strong> : <code>STRING</code></li>
</ul>
<p>If we query this table, we'll see the following results:</p>
<div>
<img alt="SQL test table" src="@source/destinations/sql/images/test-table-schema.png">
</div>
<p>Note that the first event contains an <em>empty cell</em> under <code>username</code> — technically a <code>NULL</code> value — since that event was missing in that record.</p>
<p>Now let's say we send a third event to this same table:</p>
<div class="language-json ext-json line-numbers-mode"><pre v-pre class="language-json"><code><span class="token punctuation">{</span> <span class="token property">"event_type"</span><span class="token operator">:</span> <span class="token string">"open"</span><span class="token punctuation">,</span> <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token string">"1557349722"</span><span class="token punctuation">,</span> <span class="token property">"username"</span><span class="token operator">:</span> <span class="token string">"test_user"</span> <span class="token punctuation">}</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p>It's tough to spot the difference, but <code>ts</code> is a JSON <strong>string</strong> in this example, not a <strong>number</strong> like we saw before.</p>
<p><code>ts</code> now contains numbers and strings in the underlying JSON, so we change the type of this field to <code>STRING</code> in the schema, since <strong><code>STRING</code> data captures any arbitrary sequence of characters and allows us to &quot;fall back&quot; to a more general type that captures both the number and string data in the <code>ts</code> field</strong>.</p>
<p>Compare the <code>ts</code> results before:</p>
<div>
<img alt="SQL test table" width="150" src="@source/destinations/sql/images/ts-number.png">
</div>
<p>with the results after we sent this third event, where <code>ts</code> is now a <code>STRING</code> type in our schema:</p>
<div>
<img alt="SQL test table" width="290" src="@source/destinations/sql/images/ts-string.png">
</div>
<p>We dig into these typing decisions in depth <a href="#mapping-json-data-types-to-presto">below</a>.</p>
<h3 id="existing-table" tabindex="-1"><a class="header-anchor" href="#existing-table" aria-hidden="true">#</a> Existing table</h3>
<p>Once a table exists, we process new data using the same schema logic noted above: we review the fields and values of the new JSON payloads, comparing them against the existing schema and updating that schema accordingly if we encounter a new field, or if the values of an existing field are of a new type than we've previously encountered.</p>
<h3 id="mapping-json-data-types-to-presto-types" tabindex="-1"><a class="header-anchor" href="#mapping-json-data-types-to-presto-types" aria-hidden="true">#</a> Mapping JSON data types to Presto types</h3>
<p>The automatic schema detection described above follows a set of defined rules. Since the SQL service accepts only JSON data today, we map JSON types to a Presto type that's equivalent, or as close as possible to the original type.</p>
<p>In general, the first time we see a given JSON data type, we convert it to its corresponding Presto / Hive type:</p>
<table>
<thead>
<tr>
<th>JSON type</th>
<th style="text-align:center">Presto / Hive type</th>
</tr>
</thead>
<tbody>
<tr>
<td>String</td>
<td style="text-align:center"><code>STRING</code></td>
</tr>
<tr>
<td>Number</td>
<td style="text-align:center"><code>DOUBLE</code></td>
</tr>
<tr>
<td>Boolean</td>
<td style="text-align:center"><code>BOOLEAN</code></td>
</tr>
<tr>
<td>Array</td>
<td style="text-align:center"><code>ARRAY</code></td>
</tr>
<tr>
<td>Object</td>
<td style="text-align:center"><code>STRUCT</code></td>
</tr>
<tr>
<td>null</td>
<td style="text-align:center"><code>STRING</code></td>
</tr>
</tbody>
</table>
<p><code>ARRAY</code> and <code>STRUCT</code> types are more complex, and contain information about the types of data they contain. For example, if we send this payload:</p>
<div class="language-json ext-json line-numbers-mode"><pre v-pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">"person"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"first_name"</span><span class="token operator">:</span> <span class="token string">"Luke"</span><span class="token punctuation">,</span>
    <span class="token property">"last_name"</span><span class="token operator">:</span> <span class="token string">"Skywalker"</span><span class="token punctuation">,</span>
    <span class="token property">"job"</span><span class="token operator">:</span> <span class="token string">"Jedi"</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>The resulting schema will have a single <strong>person</strong> <code>STRUCT</code> with the following schema:</p>
<div class="language-text ext-text line-numbers-mode"><pre v-pre class="language-text"><code>struct&lt;first_name:string,last_name:string,job:string>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p>We also convert strings matching some common patterns to specific Presto types:</p>
<table>
<thead>
<tr>
<th>Pattern</th>
<th style="text-align:center">Presto type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/^[0-9]{4}-[0-9]{2}-[0-9]{2}\$/</code></td>
<td style="text-align:center"><code>DATE</code></td>
</tr>
<tr>
<td><code>/^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}(.[0-9]{1,6})?\$/</code></td>
<td style="text-align:center"><code>TIMESTAMP</code></td>
</tr>
</tbody>
</table>
<p>One point worth re-iterating: <strong>all numbers are recorded as Presto <code>DOUBLE</code>s</strong>. This might seem odd at first glance — why don't we treat integers as <code>INT</code>s and floating point numbers as <code>DOUBLE</code>s or <code>FLOAT</code>s? In JavaScript, numbers are just numbers — there's no special type to differentiate an integer from a floating-point number. JSON follows this same standard. We follow the guidance of the <a href="https://tools.ietf.org/html/rfc7159#section-6" target="_blank" rel="noopener noreferrer">JSON spec<ExternalLinkIcon/></a> and use double-precision floating point numbers (in Presto, type <code>DOUBLE</code>) for all numbers. This is something we're likely to improve as the SQL service evolves over time.</p>
<h3 id="fields-with-values-of-variable-types" tabindex="-1"><a class="header-anchor" href="#fields-with-values-of-variable-types" aria-hidden="true">#</a> Fields with values of variable types</h3>
<p><strong>If a field contains more than one type of data — for example, a number and a string — we always fall back to a field type of <code>STRING</code></strong>.</p>
<p>If you're seeing fields with values of variable types in your events — e.g. a field that contains numbers and strings for different events — coming into your workflow, and that's not expected, you have a couple of options.</p>
<ol>
<li><a href="https://prestodb.github.io/docs/0.172/functions/conversion.html" target="_blank" rel="noopener noreferrer"><code>CAST</code> the data<ExternalLinkIcon/></a> to the desired type when making SQL queries, or</li>
<li>If you always expect events to contain fields with a single value, you can include a code cell in your workflow to check the type of the values of field, using the <a href="/workflows/steps/code/#end" target="_blank" rel="noopener noreferrer"><code>$end()</code> Pipedream function<ExternalLinkIcon/></a> to end the workflow if a value doesn't match the expected type. Calling <code>$end()</code> in a code step before a given step cell will not send the data to that Destination.</li>
</ol>
<h2 id="data-retention" tabindex="-1"><a class="header-anchor" href="#data-retention" aria-hidden="true">#</a> Data Retention</h2>
<p>Today, <strong>events sent to a SQL Destination are stored for 30 days. After 30 days, the data is completely deleted</strong>.</p>
<p>For example, an event sent around 12:00pm on a given day will be completely deleted 30 days after we received the event, also around 12:00pm.</p>
<p>Therefore, if your workflow is constantly sending events to a SQL Destination, you'll always have a rolling 30-day period of data to analyze.</p>
<h2 id="running-sql-queries-from-the-ui" tabindex="-1"><a class="header-anchor" href="#running-sql-queries-from-the-ui" aria-hidden="true">#</a> Running SQL queries from the UI</h2>
<p>Visit <a href="https://pipedream.com/sql" target="_blank" rel="noopener noreferrer">https://pipedream.com/sql<ExternalLinkIcon/></a> to run SQL queries from the UI. The SQL Service uses the Presto <a href="#sql-dialect">SQL dialect</a>.</p>
<p>You can query <code>STRUCT</code> fields — nested objects from the original JSON payload — using &quot;dot notation&quot;. If you send an event like this to a SQL Destination:</p>
<div class="language-json ext-json line-numbers-mode"><pre v-pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">"event_type"</span><span class="token operator">:</span> <span class="token string">"click"</span><span class="token punctuation">,</span>
  <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1557349719</span><span class="token punctuation">,</span>
  <span class="token property">"person"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"first_name"</span><span class="token operator">:</span> <span class="token string">"Luke"</span><span class="token punctuation">,</span>
    <span class="token property">"last_name"</span><span class="token operator">:</span> <span class="token string">"Skywalker"</span><span class="token punctuation">,</span>
    <span class="token property">"job"</span><span class="token operator">:</span> <span class="token string">"Jedi"</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>you can query the <code>first_name</code> and <code>job</code> fields within the <code>person</code> object like so:</p>
<div>
<img alt="Querying nested data" src="@source/destinations/sql/images/star-wars-struct.png">
</div>
<p>In general, you want to <code>SELECT struct_name.field_name</code>.</p>
<p>This can be extended to more complex JSON with multiple levels of nested fields. To query a field two nested objects deep, for example, you can <code>SELECT struct_1.struct_2.field_name</code>.</p>
<h3 id="limits" tabindex="-1"><a class="header-anchor" href="#limits" aria-hidden="true">#</a> Limits</h3>
<p>The SQL UI returns up to 999 records of results. You can <a href="#downloading-your-results">download the full result set</a> or fetch the full results <a href="#running-sql-queries-via-api">from the API</a>.</p>
<h3 id="keyboard-shortcuts" tabindex="-1"><a class="header-anchor" href="#keyboard-shortcuts" aria-hidden="true">#</a> Keyboard Shortcuts</h3>
<h4 id="meta-enter" tabindex="-1"><a class="header-anchor" href="#meta-enter" aria-hidden="true">#</a> <code>Meta</code> + <code>Enter</code></h4>
<p><strong>Run SQL query</strong>. The <a href="https://www.computerhope.com/jargon/m/meta-key.htm" target="_blank" rel="noopener noreferrer"><code>Meta</code><ExternalLinkIcon/></a> key is typically to the left of your spacebar, like the <code>Command</code> key on Macs, or the <code>Windows</code> key on PCs.</p>
<h3 id="downloading-your-results" tabindex="-1"><a class="header-anchor" href="#downloading-your-results" aria-hidden="true">#</a> Downloading your results</h3>
<p>After a query completes, you can download the results of that query by clicking on the download button in the bottom-right:</p>
<div>
<img alt="SQL Download button" src="@source/destinations/sql/images/download-button.png">
</div>
<p>Results for most queries will be downloaded as CSVs. The results of some queries — for example <a href="https://en.wikipedia.org/wiki/Data_definition_language" target="_blank" rel="noopener noreferrer">DDL statements<ExternalLinkIcon/></a> like <code>SHOW TABLES</code> — will be downloaded as <code>.txt</code> files.</p>
<h3 id="sql-dialect" tabindex="-1"><a class="header-anchor" href="#sql-dialect" aria-hidden="true">#</a> SQL dialect</h3>
<p>Different databases and query engines support a large variety of SQL statements and functions. A function that works in one database may not be supported on another. The SQL supported on one platform vs. another is referred to as a <a href="https://www.oreilly.com/library/view/sql-in-a/9780596155322/ch01s03.html" target="_blank" rel="noopener noreferrer"><strong>SQL dialect</strong><ExternalLinkIcon/></a>.</p>
<p>You can run any SQL supported by <a href="https://prestodb.github.io/docs/0.172/functions.html" target="_blank" rel="noopener noreferrer">Presto v0.172<ExternalLinkIcon/></a> on our SQL service, except for <a href="#sql-queries-we-prevent">a subset of queries we prevent</a>. This should include all the standard SQL you're used to — <code>SELECT</code> statements, aggregation functions, joins, and more — in addition to some Presto-specific functions you may have to learn for more advanced use cases.</p>
<h3 id="sql-queries-we-prevent" tabindex="-1"><a class="header-anchor" href="#sql-queries-we-prevent" aria-hidden="true">#</a> SQL queries we prevent</h3>
<p>Today, we prevent the following SQL queries:</p>
<ul>
<li><code>ALTER DATABASE</code></li>
<li><code>ALTER TABLE</code></li>
<li><code>CREATE DATABASE</code></li>
<li><code>CREATE TABLE</code></li>
<li><code>CREATE VIEW</code></li>
<li><code>DELETE FROM</code></li>
<li><code>DESCRIBE VIEW</code></li>
<li><code>DROP DATABASE</code></li>
<li><code>DROP TABLE</code></li>
<li><code>DROP VIEW</code></li>
<li><code>SHOW CREATE TABLE</code></li>
<li><code>SHOW PARTITIONS</code></li>
<li><code>SHOW TBLPROPERTIES</code></li>
<li><code>SHOW VIEWS</code></li>
</ul>
<p>If you issue one of these queries, you'll see a message noting that the query is not allowed.</p>
<h2 id="running-sql-queries-via-api" tabindex="-1"><a class="header-anchor" href="#running-sql-queries-via-api" aria-hidden="true">#</a> Running SQL queries via API</h2>
<p>Pipedream exposes an API for running SQL queries at <strong>{{$site.themeConfig.SQL_API_BASE_URL}}</strong>. You can authorize requests to this API using your <a href="/api/auth/#pipedream-api-key" target="_blank" rel="noopener noreferrer">Pipedream API key<ExternalLinkIcon/></a>.</p>
<p>This endpoint expects an HTTP <code>POST</code> request with the SQL query in the <code>query</code> field of the HTTP payload:</p>
<div class="language-javascript ext-js line-numbers-mode"><pre v-pre class="language-javascript"><code><span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">axios</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
  <span class="token literal-property property">url</span><span class="token operator">:</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">https://rt.pipedream.com/sql</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">,</span>
  <span class="token literal-property property">method</span><span class="token operator">:</span> <span class="token string">'POST'</span><span class="token punctuation">,</span>
  <span class="token literal-property property">headers</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token literal-property property">Authorization</span><span class="token operator">:</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">Bearer PIPEDREAM_API_KEY</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">,</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token literal-property property">data</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token literal-property property">query</span><span class="token operator">:</span> <span class="token string">"SELECT COUNT(*) FROM your_table"</span><span class="token punctuation">,</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>Some HTTP clients like <code>axios</code> automatically set a <code>Content-Type</code> header of <code>application/json</code> when you pass a JavaScript object in the <code>data</code> field, but you'll also need to ensure you set that header manually if necessary. For example, you'd make the same query above using <code>cURL</code> like so:</p>
<div class="language-bash ext-sh line-numbers-mode"><pre v-pre class="language-bash"><code><span class="token function">curl</span> -H <span class="token string">'Authorization: Bearer PIPEDREAM_API_KEY'</span> <span class="token punctuation">\</span>
  -H <span class="token string">'Content-Type: application/json'</span> <span class="token punctuation">\</span>
  -d <span class="token string">'{"query": "SELECT COUNT(*) FROM your_table"}'</span> <span class="token punctuation">\</span>
  https://rt.pipedream.com/sql
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>The SQL API returns a JSON string that contains metadata on column names, and an array of arrays containing your results and their data types.</p>
<p>The <a href="#query-limits">same limits</a> governing SQL queries made in the UI apply to queries made using the API.</p>
<h2 id="running-sql-queries-from-a-workflow" tabindex="-1"><a class="header-anchor" href="#running-sql-queries-from-a-workflow" aria-hidden="true">#</a> Running SQL queries from a workflow</h2>
<p>You can also run queries against the SQL service within a workflow. You can use this to run aggregate queries for basic scheduled reports, kick off SQL queries from Slack bots, and more.</p>
<p>In a workflow, there are two actions you can use to run SQL queries, both found under the <strong>Pipedream</strong> app:</p>
<ul>
<li><strong>Query SQL</strong> : returns a formatted set of results you can pass to other steps</li>
<li><strong>Get CSV for a SQL query execution</strong> : given the execution ID of a SQL query (returned from the <strong>Query SQL</strong> action), return a formatted CSV. This action can be helpful for formatting the results of a query to send to other systems.</li>
</ul>
<div>
<img alt="SQL actions" src="@source/destinations/sql/images/sql-actions.png" width="400px">
</div>
<p><a href="https://pipedream.com/@dylburger/send-results-of-pipedream-sql-query-to-google-sheets-p_YyCD6r/edit" target="_blank" rel="noopener noreferrer">This workflow<ExternalLinkIcon/></a> shows an example of how to send the results of a query to Google Sheets, for example.</p>
<p>The <a href="#query-limits">same limits</a> governing SQL queries made in the UI apply to workflows. Additionally, to support longer queries, you may need to extend the <a href="/workflows/settings/#execution-timeout-limit" target="_blank" rel="noopener noreferrer">default execution timeout<ExternalLinkIcon/></a> in your workflow's settings.</p>
<h2 id="triggering-workflows-on-scheduled-sql-queries" tabindex="-1"><a class="header-anchor" href="#triggering-workflows-on-scheduled-sql-queries" aria-hidden="true">#</a> Triggering workflows on scheduled SQL queries</h2>
<p>Just like you can trigger workflows on <a href="/workflows/steps/triggers/#http" target="_blank" rel="noopener noreferrer">HTTP requests<ExternalLinkIcon/></a> or <a href="/workflows/steps/triggers/#schedule" target="_blank" rel="noopener noreferrer">cron jobs<ExternalLinkIcon/></a>, you can trigger a workflow from the results of a scheduled SQL query using the <a href="https://github.com/PipedreamHQ/pipedream/blob/master/components/pipedream/sources/new-records-from-sql-query/README.md" target="_blank" rel="noopener noreferrer">Scheduled SQL Source<ExternalLinkIcon/></a>.</p>
<p>For example, you can schedule a query to run once a day, emitting the results to one or more workflows to send the results to Slack, S3, and more.</p>
<p><a href="https://github.com/PipedreamHQ/pipedream/blob/master/components/pipedream/sources/new-records-from-sql-query/README.md" target="_blank" rel="noopener noreferrer">Read the docs on this source here<ExternalLinkIcon/></a>.</p>
<h2 id="query-limits" tabindex="-1"><a class="header-anchor" href="#query-limits" aria-hidden="true">#</a> Query Limits</h2>
<ul>
<li>Queries are currently limited to a runtime of 60 seconds.</li>
<li>You cannot issue a query that returns over <code>1GB</code> of data.</li>
</ul>
<h2 id="limitations-on-pipedream-sql-table-names" tabindex="-1"><a class="header-anchor" href="#limitations-on-pipedream-sql-table-names" aria-hidden="true">#</a> Limitations on Pipedream SQL table names</h2>
<p>Table names have just a few limitations:</p>
<ul>
<li>They can contain alphanumeric characters.</li>
<li>Additionally, the only allowed special character is the underscore (<code>_</code>), but</li>
<li>You cannot <em>begin</em> a table name with an underscore.</li>
</ul>
<p>Some examples:</p>
<ul>
<li><strong><code>my_table</code></strong> is OK, but <strong><code>my-table</code></strong> is not (<em>hyphen not allowed</em>)</li>
<li><strong><code>my_table_123</code></strong> is OK, but <strong><code>my_table@#</code></strong> is not (<em>no other special characters besides underscore</em>).</li>
<li><strong><code>table</code></strong> is OK, but <strong><code>_table</code></strong> is not (<em>no leading underscore</em>).</li>
</ul>
<p>If you've chosen a table name that doesn't match these rules, we'll show an error message in the UI:</p>
<div>
<img alt="Invalid table name" src="@source/destinations/sql/images/invalid-table-name.png">
</div>
<p>If you want to test potential table names against a <a href="https://en.wikipedia.org/wiki/Regular_expression" target="_blank" rel="noopener noreferrer">regular expression<ExternalLinkIcon/></a>, this pattern captures the same logic as above:</p>
<div class="language-text ext-text line-numbers-mode"><pre v-pre class="language-text"><code>/^(?!_)[a-z0-9_]+$/gi
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><h2 id="how-we-handle-non-json-data-sent-to-sql-destinations" tabindex="-1"><a class="header-anchor" href="#how-we-handle-non-json-data-sent-to-sql-destinations" aria-hidden="true">#</a> How we handle non-JSON data sent to SQL Destinations</h2>
<p>The SQL Service expects JavaScript objects as payloads. If you send a string, a CSV row, or another type of data as the payload, you may see unexpected issues when querying your data via SQL. If you do, please <a href="https://pipedream.com/support/" target="_blank" rel="noopener noreferrer">reach out to our Support team<ExternalLinkIcon/></a> and we can help you troubleshoot.</p>
<p>Often, though, we'll just ignore the record when you issue queries. If you see <strong>empty rows</strong> in your result set, that's often an indication of a record we couldn't query using the schema defined for this table.</p>
<p>Technically these empty rows contain <code>NULL</code> values for every field. So you can exclude these records by including a filter on your query like:</p>
<div class="language-sql ext-sql line-numbers-mode"><pre v-pre class="language-sql"><code><span class="token keyword">WHERE</span> field <span class="token operator">IS</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span>
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><h2 id="still-have-questions" tabindex="-1"><a class="header-anchor" href="#still-have-questions" aria-hidden="true">#</a> Still have questions?</h2>
<p>Please <a href="https://pipedream.com/support/" target="_blank" rel="noopener noreferrer">reach out<ExternalLinkIcon/></a> if this doc didn't answer your question. We're happy to help!</p>
</template>
